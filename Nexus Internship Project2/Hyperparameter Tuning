import spacy
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, accuracy_score

# Load your sentiment analysis dataset (replace 'your_dataset.csv' with your actual file)
df = pd.read_csv('test.csv')

# Load spaCy's pre-trained model for text processing
nlp = spacy.load("en_core_web_sm")

# Split the dataset into training and testing sets
train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)

# Define the pipeline with CountVectorizer and Logistic Regression
pipeline = Pipeline([
    ('vectorizer', CountVectorizer(analyzer='word', tokenizer=nlp.tokenizer, stop_words='english')),
    ('classifier', LogisticRegression())
])

# Define hyperparameters to search
param_grid = {
    'vectorizer__ngram_range': [(1, 1), (1, 2)],  # unigrams or bigrams
    'classifier__C': [0.1, 1, 10],  # regularization parameter for Logistic Regression
}

# Perform grid search with cross-validation
grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')
grid_search.fit(train_df['text'], train_df['sentiment'])

# Get the best hyperparameters
best_params = grid_search.best_params_

# Evaluate the model with the best hyperparameters on the test set
best_model = grid_search.best_estimator_
predictions = best_model.predict(test_df['text'])

# Display the best hyperparameters and evaluation results
print("Best Hyperparameters:", best_params)
print("Accuracy on Test Set:", accuracy_score(test_df['sentiment'], predictions))
print("Classification Report on Test Set:")
print(classification_report(test_df['sentiment'], predictions))
